{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import glob\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob('../data/yellow_tripdata_2016-*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv_file in csv_files:\n",
    "    # Change the file suffix\n",
    "    p = Path(csv_file)\n",
    "    parquet_file = p.parent / f\"{p.name[:-3]}parquet\"\n",
    "    str_parquet_file = p.parent / f\"str_{p.name[:-3]}parquet\"\n",
    "    cat_parquet_file = p.parent / f\"cat_{p.name[:-3]}parquet\"\n",
    "    \n",
    "    # Read in the CSV and already convert datetime columns\n",
    "    df = pd.read_csv(\n",
    "        csv_file,\n",
    "        parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "        index_col=False,\n",
    "        infer_datetime_format=True,\n",
    "    )\n",
    "    \n",
    "    # store_and_fwd_flag is actually boolean but read in as string.\n",
    "    # Manually change it to have a more efficient storage.\n",
    "    df['store_and_fwd_flag'] = df['store_and_fwd_flag'] == 'Y'\n",
    "    \n",
    "    # Store it with the default options:\n",
    "    #  * a single RowGroup, no chunking\n",
    "    #  * SNAPPY compression\n",
    "    df.to_parquet(parquet_file, engine=\"pyarrow\")\n",
    "    \n",
    "    df['str'] = df.apply(lambda x: hashlib.sha256(str(x).encode()).hexdigest(), axis = 1)\n",
    "    df.to_parquet(str_parquet_file, engine=\"pyarrow\")\n",
    "    \n",
    "    df['str'] = df['str'].apply(lambda s: f\"{s[0]}-{s[1]}-{s[2]}\")\n",
    "    df.to_parquet(cat_parquet_file, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv_file in csv_files:\n",
    "    # Change the file suffix\n",
    "    p = Path(csv_file)\n",
    "    parquet_file = p.parent / f\"{p.name[:-3]}parquet\"\n",
    "    str_parquet_file = p.parent / f\"str_{p.name[:-3]}parquet\"\n",
    "    str_csv_file = p.parent / f\"str_{p.name}\"\n",
    "    cat_parquet_file = p.parent / f\"cat_{p.name[:-3]}parquet\"\n",
    "    cat_csv_files = p.parent / f\"cat_{p.name}\"\n",
    "    \n",
    "    df = pd.read_parquet(str_parquet_file)\n",
    "    df.to_csv(str_csv_file, index=False)\n",
    "    \n",
    "    df = pd.read_parquet(cat_parquet_file)\n",
    "    df.to_csv(cat_csv_files, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
